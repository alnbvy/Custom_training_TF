{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GC7zSrbOWiz0"
   },
   "source": [
    "# Week 4 Assignment: Create a VGG network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VGG network](https://towardsdatascience.com/vgg-neural-networks-the-next-step-after-alexnet-3f91fa9ffe2c) that can be trained to classify images. The model will look something like this:\n",
    "\n",
    "<img src='VGG.png'>\n",
    "\n",
    "It is primarily made up of a series of Conv2D layers followed by a softmax activated layers to classify the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z01I5nj0NAOu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "WGJGaxVjM00W",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f19295d8925e1d2e60eefd42a6b4dd8",
     "grade": false,
     "grade_id": "cell-1449db9892707876",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Block(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
    "        super(Block, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.repetitions = repetitions\n",
    "        \n",
    "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
    "        for i in range(repetitions):\n",
    "            \n",
    "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
    "            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(filters, kernel_size, padding='same',activation = 'relu')\n",
    "        \n",
    "        # Define the max pool layer that will be added after the Conv2D blocks\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size, strides)\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        # access the class's conv2D_0 layer\n",
    "        conv2D_0 = vars(self)['conv2D_0']\n",
    "        \n",
    "        # Connect the conv2D_0 layer to inputs\n",
    "        x = conv2D_0(inputs)\n",
    "\n",
    "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
    "        for i in range(1,self.repetitions):\n",
    "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
    "            conv2D_i = vars(self)[f'conv2D_{i}']\n",
    "            \n",
    "            # Use the conv2D_i and connect it to the previous layer\n",
    "            x = conv2D_i(x)\n",
    "\n",
    "        # Finally, add the max_pool layer\n",
    "        max_pool = self.max_pool(x)\n",
    "        \n",
    "        return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "yD-paeGiNGvz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "523346a38f53bc31e080114e98e8eca6",
     "grade": false,
     "grade_id": "cell-d9e90af0898eb47f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MyVGG(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyVGG, self).__init__()\n",
    "\n",
    "        # Creating blocks of VGG with the following \n",
    "        # (filters, kernel_size, repetitions) configurations\n",
    "        self.block_a = Block(filters = 64, kernel_size = 3, repetitions = 2)\n",
    "        self.block_b = Block(filters = 128, kernel_size = 3, repetitions = 2)\n",
    "        self.block_c = Block(filters = 256, kernel_size = 3, repetitions = 3)\n",
    "        self.block_d = Block(filters = 512, kernel_size = 3, repetitions = 3)\n",
    "        self.block_e = Block(filters = 512, kernel_size = 3, repetitions = 3)\n",
    "\n",
    "        # Classification head\n",
    "        # Define a Flatten layer\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # Create a Dense layer with 256 units and ReLU as the activation function\n",
    "        self.fc = tf.keras.layers.Dense(256, activation='relu')\n",
    "        # Finally add the softmax classifier using a Dense layer\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Chain all the layers one after the other\n",
    "        x = self.block_a(inputs)\n",
    "        x = self.block_b(x)\n",
    "        x = self.block_c(x)\n",
    "        x = self.block_d(x)\n",
    "        x = self.block_e(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MaF763OKNJxU"
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
    "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data2/')\n",
    "\n",
    "# Initialize VGG with the number of classes \n",
    "vgg = MyVGG(num_classes=2)\n",
    "\n",
    "# Compile with losses and metrics\n",
    "vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess(features):\n",
    "    # Resize and normalize\n",
    "    image = tf.image.resize(features['image'], (224, 224))\n",
    "    return tf.cast(image, tf.float32) / 255., features['label']\n",
    "\n",
    "# Apply transformations to dataset\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "\n",
    "# Train the custom VGG model\n",
    "#vgg.fit(dataset, epochs=10, batch_size = 32) # It takes to long to train on iMac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to normalize the images and return (image, label) pairs.\n",
    "# It is the requirement of the vgg to have a 224 by 224 input image\n",
    "def preprocess(features):\n",
    "    image = tf.image.resize(features['image'], (224, 224))\n",
    "    return tf.cast(image, tf.float32) / 255., features['label']\n",
    "\n",
    "# create a ResNet instance with 10 output units for MNIST\n",
    "vgg_mnist = MyVGG(num_classes=10)\n",
    "vgg_mnist.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# load and preprocess the dataset\n",
    "dataset = tfds.load('mnist', split=tfds.Split.TRAIN, data_dir='./data')\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "\n",
    "# train the model.\n",
    "#vgg_mnist.fit(dataset, epochs=1) # It takes to long to train on iMac"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExerciseAnswer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
